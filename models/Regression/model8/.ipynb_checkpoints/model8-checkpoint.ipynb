{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ec21e65-1a27-430b-b632-beb060038b0b",
   "metadata": {},
   "source": [
    "# Upgrading our random forest \n",
    "Here are the main upgrades:\n",
    "\n",
    "Automated Hyperparameter Tuning: Instead of using fixed settings for the Random Forest, we'll use RandomizedSearchCV. This technique intelligently searches for the best combination of model parameters (n_estimators, max_depth, etc.), which almost always results in a more accurate model.\n",
    "\n",
    "Robust Cross-Validation: The search process uses 5-fold cross-validation (cv=5), meaning it trains and tests the model 5 times on different subsets of your data. This ensures the model's performance is stable and not just a result of a \"lucky\" train-test split.\n",
    "\n",
    "Feature Importance Analysis: After finding the best model, we'll extract and plot the feature importances. This tells you exactly which input columns (e.g., dam_type, year_completed) are the most influential in predicting the target, which is crucial for understanding the why behind the model's logic. ðŸ§\n",
    "\n",
    "Enhanced Reporting: The most important features and the best-found hyperparameters are now saved in the output files for easy reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36951dab-bad0-4ff5-b3c7-d87da69cf37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing target: dam_height | Task Type: REGRESSION (Random Forest with Tuning) ---\n",
      "Searching for the best hyperparameters...\n",
      "Best hyperparameters found: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 30}\n",
      "Training complete with the best model.\n",
      "âœ… Performance metrics for 'dam_height' collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Temp\\ipykernel_20936\\2978072443.py:132: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved as plot_importance_dam_height.svg\n",
      "Prediction plot saved as plot_pred_dam_height.svg\n",
      "Detailed report saved to report_dam_height.xlsx\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing target: max_storage_ac_ft | Task Type: REGRESSION (Random Forest with Tuning) ---\n",
      "Searching for the best hyperparameters...\n",
      "Best hyperparameters found: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10}\n",
      "Training complete with the best model.\n",
      "âœ… Performance metrics for 'max_storage_ac_ft' collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Temp\\ipykernel_20936\\2978072443.py:132: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved as plot_importance_max_storage_ac_ft.svg\n",
      "Prediction plot saved as plot_pred_max_storage_ac_ft.svg\n",
      "Detailed report saved to report_max_storage_ac_ft.xlsx\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing target: surface_area_acres | Task Type: REGRESSION (Random Forest with Tuning) ---\n",
      "Searching for the best hyperparameters...\n",
      "Best hyperparameters found: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10}\n",
      "Training complete with the best model.\n",
      "âœ… Performance metrics for 'surface_area_acres' collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Temp\\ipykernel_20936\\2978072443.py:132: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved as plot_importance_surface_area_acres.svg\n",
      "Prediction plot saved as plot_pred_surface_area_acres.svg\n",
      "Detailed report saved to report_surface_area_acres.xlsx\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing target: incident_date_year | Task Type: REGRESSION (Random Forest with Tuning) ---\n",
      "Searching for the best hyperparameters...\n",
      "Best hyperparameters found: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': 20}\n",
      "Training complete with the best model.\n",
      "âœ… Performance metrics for 'incident_date_year' collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Temp\\ipykernel_20936\\2978072443.py:132: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved as plot_importance_incident_date_year.svg\n",
      "Prediction plot saved as plot_pred_incident_date_year.svg\n",
      "Detailed report saved to report_incident_date_year.xlsx\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing target: incident_date_month | Task Type: REGRESSION (Random Forest with Tuning) ---\n",
      "Searching for the best hyperparameters...\n",
      "Best hyperparameters found: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': 20}\n",
      "Training complete with the best model.\n",
      "âœ… Performance metrics for 'incident_date_month' collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Temp\\ipykernel_20936\\2978072443.py:132: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved as plot_importance_incident_date_month.svg\n",
      "Prediction plot saved as plot_pred_incident_date_month.svg\n",
      "Detailed report saved to report_incident_date_month.xlsx\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing target: incident_date_day | Task Type: REGRESSION (Random Forest with Tuning) ---\n",
      "Searching for the best hyperparameters...\n",
      "Best hyperparameters found: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': 20}\n",
      "Training complete with the best model.\n",
      "âœ… Performance metrics for 'incident_date_day' collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Temp\\ipykernel_20936\\2978072443.py:132: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved as plot_importance_incident_date_day.svg\n",
      "Prediction plot saved as plot_pred_incident_date_day.svg\n",
      "Detailed report saved to report_incident_date_day.xlsx\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing target: incident_time_hour | Task Type: REGRESSION (Random Forest with Tuning) ---\n",
      "Searching for the best hyperparameters...\n",
      "Best hyperparameters found: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': 20}\n",
      "Training complete with the best model.\n",
      "âœ… Performance metrics for 'incident_time_hour' collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Temp\\ipykernel_20936\\2978072443.py:132: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved as plot_importance_incident_time_hour.svg\n",
      "Prediction plot saved as plot_pred_incident_time_hour.svg\n",
      "Detailed report saved to report_incident_time_hour.xlsx\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing target: number_of_people_evacuated | Task Type: REGRESSION (Random Forest with Tuning) ---\n",
      "Searching for the best hyperparameters...\n",
      "Best hyperparameters found: {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20}\n",
      "Training complete with the best model.\n",
      "âœ… Performance metrics for 'number_of_people_evacuated' collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Temp\\ipykernel_20936\\2978072443.py:132: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved as plot_importance_number_of_people_evacuated.svg\n",
      "Prediction plot saved as plot_pred_number_of_people_evacuated.svg\n",
      "Detailed report saved to report_number_of_people_evacuated.xlsx\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing target: number_of_habitable_structures_evacuated | Task Type: REGRESSION (Random Forest with Tuning) ---\n",
      "Searching for the best hyperparameters...\n",
      "Best hyperparameters found: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 20}\n",
      "Training complete with the best model.\n",
      "âœ… Performance metrics for 'number_of_habitable_structures_evacuated' collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Temp\\ipykernel_20936\\2978072443.py:132: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved as plot_importance_number_of_habitable_structures_evacuated.svg\n",
      "Prediction plot saved as plot_pred_number_of_habitable_structures_evacuated.svg\n",
      "Detailed report saved to report_number_of_habitable_structures_evacuated.xlsx\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing target: number_of_habitable_structures_flooded | Task Type: REGRESSION (Random Forest with Tuning) ---\n",
      "Searching for the best hyperparameters...\n",
      "Best hyperparameters found: {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': None}\n",
      "Training complete with the best model.\n",
      "âœ… Performance metrics for 'number_of_habitable_structures_flooded' collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Temp\\ipykernel_20936\\2978072443.py:132: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved as plot_importance_number_of_habitable_structures_flooded.svg\n",
      "Prediction plot saved as plot_pred_number_of_habitable_structures_flooded.svg\n",
      "Detailed report saved to report_number_of_habitable_structures_flooded.xlsx\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing target: volume_released_at_failure_ac_ft | Task Type: REGRESSION (Random Forest with Tuning) ---\n",
      "Searching for the best hyperparameters...\n",
      "Best hyperparameters found: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 30}\n",
      "Training complete with the best model.\n",
      "âœ… Performance metrics for 'volume_released_at_failure_ac_ft' collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Temp\\ipykernel_20936\\2978072443.py:132: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved as plot_importance_volume_released_at_failure_ac_ft.svg\n",
      "Prediction plot saved as plot_pred_volume_released_at_failure_ac_ft.svg\n",
      "Detailed report saved to report_volume_released_at_failure_ac_ft.xlsx\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing target: incident_duration | Task Type: REGRESSION (Random Forest with Tuning) ---\n",
      "Searching for the best hyperparameters...\n",
      "Best hyperparameters found: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10}\n",
      "Training complete with the best model.\n",
      "âœ… Performance metrics for 'incident_duration' collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Local\\Temp\\ipykernel_20936\\2978072443.py:132: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved as plot_importance_incident_duration.svg\n",
      "Prediction plot saved as plot_pred_incident_duration.svg\n",
      "Detailed report saved to report_incident_duration.xlsx\n",
      "--------------------------------------------------\n",
      "\n",
      "âœ… All performance metrics saved to 'model_performance_metrics.xlsx'.\n",
      "\n",
      "All tasks complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_FILE = '../regression_data.csv' # Make sure this path is correct\n",
    "\n",
    "INPUT_COLUMNS = [\n",
    "    'state', 'downstream_hazard_potential', 'owner_type', 'dam_type',\n",
    "    'primary_purpose_s', 'eap', 'year_completed', 'latitude', 'longitude', 'year_modified'\n",
    "]\n",
    "\n",
    "NEW_TARGET_COLUMNS = [\n",
    "    'dam_height', 'max_storage_ac_ft', 'surface_area_acres',\n",
    "    'incident_date_year', 'incident_date_month', 'incident_date_day',\n",
    "    'incident_time_hour', 'number_of_people_evacuated',\n",
    "    'number_of_habitable_structures_evacuated',\n",
    "    'number_of_habitable_structures_flooded',\n",
    "    'volume_released_at_failure_ac_ft', 'incident_duration'\n",
    "]\n",
    "\n",
    "# --- Main Processing Function ---\n",
    "def train_and_evaluate_model(X, y, target_name, metrics_list):\n",
    "    \"\"\"\n",
    "    Finds the best RandomForestRegressor using RandomizedSearchCV, evaluates it,\n",
    "    and analyzes feature importances.\n",
    "    \"\"\"\n",
    "    print(f\"--- Processing target: {target_name} | Task Type: REGRESSION (Random Forest with Tuning) ---\")\n",
    "\n",
    "    # --- Preprocessing ---\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "    numerical_features = X.select_dtypes(include=np.number).columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough',\n",
    "        verbose_feature_names_out=False # Keeps original feature names cleaner\n",
    "    )\n",
    "\n",
    "    # --- Train-Test Split ---\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply preprocessing\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "    # Get the final feature names after one-hot encoding for importance plotting\n",
    "    processed_feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "\n",
    "    # --- UPGRADE: Hyperparameter Tuning with RandomizedSearchCV ---\n",
    "    print(\"Searching for the best hyperparameters...\")\n",
    "    \n",
    "    # Define the parameter distribution to search over\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', 1.0] # Use '1.0' for all features (equivalent to old 'auto')\n",
    "    }\n",
    "\n",
    "    # Instantiate the base model\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "    # Set up the Randomized Search with 5-fold cross-validation\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,  # Number of parameter settings that are sampled. Increase for better results, decrease for speed.\n",
    "        cv=5,       # 5-fold cross-validation\n",
    "        verbose=0,  # Set to 1 or 2 to see the search progress\n",
    "        random_state=42,\n",
    "        n_jobs=-1   # Use all available CPU cores\n",
    "    )\n",
    "\n",
    "    # Execute the search on the training data\n",
    "    random_search.fit(X_train_processed, y_train)\n",
    "\n",
    "    # The best model found by the search\n",
    "    best_model = random_search.best_estimator_\n",
    "    \n",
    "    print(f\"Best hyperparameters found: {random_search.best_params_}\")\n",
    "    print(\"Training complete with the best model.\")\n",
    "\n",
    "    # --- Evaluation & Reporting using the best model ---\n",
    "    y_pred = best_model.predict(X_test_processed)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    evs = explained_variance_score(y_test, y_pred)\n",
    "    n, p = X_test_processed.shape\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1) if (n - p - 1) > 0 else np.nan\n",
    "    \n",
    "    y_test_non_zero_mask = y_test != 0\n",
    "    if np.any(y_test_non_zero_mask):\n",
    "        mape = np.mean(np.abs((y_test[y_test_non_zero_mask] - y_pred[y_test_non_zero_mask]) / y_test[y_test_non_zero_mask])) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "\n",
    "    metrics_result = {\n",
    "        'Model Output': target_name,\n",
    "        'Task Type': 'Regression (Tuned RF)',\n",
    "        'MAE': mae, 'MSE': mse, 'R2_Score': r2, 'Adjusted_R2_Score': adj_r2,\n",
    "        'Explained_Variance_Score': evs, 'MAPE (%)': mape\n",
    "    }\n",
    "    metrics_list.append(metrics_result)\n",
    "    print(f\"âœ… Performance metrics for '{target_name}' collected.\")\n",
    "\n",
    "    # --- UPGRADE: Feature Importance Analysis ---\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': processed_feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Plot top 15 features\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n",
    "    plt.title(f'Top 15 Feature Importances for {target_name}')\n",
    "    plt.tight_layout()\n",
    "    plot_filename_importance = f'plot_importance_{target_name}.svg'\n",
    "    plt.savefig(plot_filename_importance, format='svg')\n",
    "    plt.close()\n",
    "    print(f\"Feature importance plot saved as {plot_filename_importance}\")\n",
    "\n",
    "\n",
    "    # --- Generate Actual vs. Predicted Plot ---\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', linewidth=2, label='Ideal Fit')\n",
    "    plt.title(f'Actual vs. Predicted for {target_name} (Tuned Random Forest)')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.legend()\n",
    "    plot_filename_pred = f'plot_pred_{target_name}.svg'\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_filename_pred, format='svg')\n",
    "    plt.close()\n",
    "    print(f\"Prediction plot saved as {plot_filename_pred}\")\n",
    "\n",
    "    # --- Save Detailed Report ---\n",
    "    report_filename = f'report_{target_name}.xlsx'\n",
    "    \n",
    "    # Create DataFrames for each sheet\n",
    "    results_df = X_test.copy()\n",
    "    results_df['actual_outcome'] = y_test\n",
    "    results_df['predicted_outcome'] = y_pred\n",
    "    \n",
    "    summary_data = {\n",
    "        'Metric': list(metrics_result.keys()),\n",
    "        'Value': list(metrics_result.values())\n",
    "    }\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    best_params_df = pd.DataFrame([random_search.best_params_])\n",
    "\n",
    "    # Write to an Excel file with multiple sheets\n",
    "    with pd.ExcelWriter(report_filename, engine='openpyxl') as writer:\n",
    "        results_df.to_excel(writer, sheet_name='Test_Inputs_and_Predictions', index=False)\n",
    "        feature_importance_df.to_excel(writer, sheet_name='Feature_Importances', index=False)\n",
    "        summary_df.to_excel(writer, sheet_name='Performance_Metrics', index=False)\n",
    "        best_params_df.to_excel(writer, sheet_name='Best_Hyperparameters', index=False)\n",
    "\n",
    "    print(f\"Detailed report saved to {report_filename}\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- Main Execution (No changes needed below) ---\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        df = pd.read_csv(DATA_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The data file '{DATA_FILE}' was not found.\")\n",
    "        exit()\n",
    "\n",
    "    model_metrics_data = []\n",
    "\n",
    "    for target in NEW_TARGET_COLUMNS:\n",
    "        if target not in df.columns:\n",
    "            print(f\"Warning: Target column '{target}' not found. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        if not pd.api.types.is_numeric_dtype(df[target]):\n",
    "            print(f\"Warning: Target column '{target}' is not numeric. Skipping regression task.\")\n",
    "            continue\n",
    "\n",
    "        current_inputs = [col for col in INPUT_COLUMNS if col in df.columns]\n",
    "        temp_df = df[current_inputs + [target]].dropna()\n",
    "        \n",
    "        if len(temp_df) < 50:\n",
    "             print(f\"Warning: Too little data for '{target}' after dropping NaNs. Skipping.\")\n",
    "             continue\n",
    "\n",
    "        X_filtered = temp_df[current_inputs]\n",
    "        y = temp_df[target]\n",
    "        \n",
    "        train_and_evaluate_model(X_filtered, y, target, model_metrics_data)\n",
    "\n",
    "    if model_metrics_data:\n",
    "        metrics_df = pd.DataFrame(model_metrics_data)\n",
    "        metrics_filename = 'model_performance_metrics.xlsx'\n",
    "        metrics_df.to_excel(metrics_filename, index=False)\n",
    "        print(f\"âœ… All performance metrics saved to '{metrics_filename}'.\")\n",
    "\n",
    "    print(\"\\nAll tasks complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42c511e-3597-49b6-9f32-5e8f9fd52956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g\n"
     ]
    }
   ],
   "source": [
    "print(\"g\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
